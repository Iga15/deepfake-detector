{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8791b2d2-1b65-42f0-9d69-3584237fb5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: /Users/igazielinska/Documents/projects/deepfake-detector/notebooks/data\n",
      "WEIGHTS_PATH: /Users/igazielinska/Documents/projects/deepfake-detector/notebooks/models/deepfake_detector_final.h5\n",
      "RUNS_DIR: /Users/igazielinska/Documents/projects/deepfake-detector/notebooks/runs\n"
     ]
    }
   ],
   "source": [
    "# ---- Global config & paths ----\n",
    "import pathlib, yaml\n",
    "\n",
    "ROOT = pathlib.Path().resolve()\n",
    "CFG = yaml.safe_load(open(ROOT.parent / \"configs\" / \"base.yaml\"))\n",
    "\n",
    "DATA_DIR = ROOT / CFG[\"paths\"][\"data_dir\"]\n",
    "WEIGHTS_DIR = ROOT / CFG[\"paths\"][\"weights_dir\"]\n",
    "WEIGHTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "WEIGHTS_PATH = WEIGHTS_DIR / CFG[\"paths\"][\"weights_name\"]\n",
    "\n",
    "RUNS_DIR = ROOT / CFG[\"paths\"][\"runs_dir\"]\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"WEIGHTS_PATH:\", WEIGHTS_PATH)\n",
    "print(\"RUNS_DIR:\", RUNS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e312f02-2593-46ed-a436-22ec03ef558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4408c675-56ad-401e-89fc-2ab142e1b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices = [0, 4, 9, 10, 33, 46, 54, 55, 58, 127, 149, 175, 205, 263, 276, 284, 285, 288, 356, 400, 425, 468, 473]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a04d8a-7156-4b97-92c6-36bd951f4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_landmarks(selected_indices):\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True)\n",
    "\n",
    "    def process_folder(folder_path, label):\n",
    "        images, landmarks, labels = [], [], []\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(root, file)\n",
    "                    image = cv2.imread(img_path)\n",
    "                    if image is None:\n",
    "                        continue\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    resized_image = cv2.resize(image, (256, 256))\n",
    "                    results = face_mesh.process(resized_image)\n",
    "                    if results.multi_face_landmarks:\n",
    "                        face_landmarks = results.multi_face_landmarks[0]\n",
    "                        landmark_coords = [\n",
    "                            (lm.x, lm.y, lm.z)\n",
    "                            for i, lm in enumerate(face_landmarks.landmark)\n",
    "                            if i in selected_indices\n",
    "                        ]\n",
    "                        images.append(resized_image)\n",
    "                        landmarks.append(landmark_coords)\n",
    "                        labels.append(label)\n",
    "        return (\n",
    "            np.asarray(images, dtype=np.uint8),\n",
    "            np.asarray(landmarks, dtype=np.float32),\n",
    "            np.asarray(labels, dtype=np.int64),\n",
    "        )\n",
    "\n",
    "    def load_data(subset):\n",
    "        subset_images, subset_landmarks, subset_labels = [], [], []\n",
    "        subset_path = DATA_DIR / subset\n",
    "        for label in [0, 1]:\n",
    "            label_path = subset_path / str(label)\n",
    "            if not label_path.exists():\n",
    "                continue\n",
    "            for subfolder in os.listdir(label_path):\n",
    "                subfolder_path = label_path / subfolder\n",
    "                if subfolder_path.is_dir():\n",
    "                    images, landmarks, labels = process_folder(str(subfolder_path), label)\n",
    "                    subset_images.append(images)\n",
    "                    subset_landmarks.append(landmarks)\n",
    "                    subset_labels.append(labels)\n",
    "        return (\n",
    "            np.concatenate(subset_images, axis=0),\n",
    "            np.concatenate(subset_landmarks, axis=0),\n",
    "            np.concatenate(subset_labels, axis=0),\n",
    "        )\n",
    "\n",
    "    X_train_images, X_train_landmarks, y_train = load_data(\"train\")\n",
    "    X_test_images, X_test_landmarks, y_test = load_data(\"test\")\n",
    "    X_val_images, X_val_landmarks, y_val = load_data(\"validate\")\n",
    "\n",
    "    return (\n",
    "        X_train_images, X_train_landmarks, y_train,\n",
    "        X_test_images, X_test_landmarks, y_test,\n",
    "        X_val_images, X_val_landmarks, y_val,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a57d9fb8-906d-47b6-a28e-ce51b29d1eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760718353.586755 7448313 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1760718353.599260 7449333 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760718353.604828 7449328 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train_images, X_train_landmarks, y_train, \\\n\u001b[1;32m      2\u001b[0m X_test_images, X_test_landmarks, y_test, \\\n\u001b[0;32m----> 3\u001b[0m X_val_images, X_val_landmarks, y_val \u001b[38;5;241m=\u001b[39m load_images_and_landmarks(selected_indices)\n",
      "Cell \u001b[0;32mIn[4], line 53\u001b[0m, in \u001b[0;36mload_images_and_landmarks\u001b[0;34m(selected_indices)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 subset_labels\u001b[38;5;241m.\u001b[39mappend(labels)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     48\u001b[0m         np\u001b[38;5;241m.\u001b[39mconcatenate(subset_images, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     49\u001b[0m         np\u001b[38;5;241m.\u001b[39mconcatenate(subset_landmarks, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     50\u001b[0m         np\u001b[38;5;241m.\u001b[39mconcatenate(subset_labels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     51\u001b[0m     )\n\u001b[0;32m---> 53\u001b[0m X_train_images, X_train_landmarks, y_train \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m X_test_images, X_test_landmarks, y_test \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m X_val_images, X_val_landmarks, y_val \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m, in \u001b[0;36mload_images_and_landmarks.<locals>.load_data\u001b[0;34m(subset)\u001b[0m\n\u001b[1;32m     45\u001b[0m             subset_landmarks\u001b[38;5;241m.\u001b[39mappend(landmarks)\n\u001b[1;32m     46\u001b[0m             subset_labels\u001b[38;5;241m.\u001b[39mappend(labels)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m---> 48\u001b[0m     np\u001b[38;5;241m.\u001b[39mconcatenate(subset_images, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     49\u001b[0m     np\u001b[38;5;241m.\u001b[39mconcatenate(subset_landmarks, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     50\u001b[0m     np\u001b[38;5;241m.\u001b[39mconcatenate(subset_labels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     51\u001b[0m )\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "X_train_images, X_train_landmarks, y_train, \\\n",
    "X_test_images, X_test_landmarks, y_test, \\\n",
    "X_val_images, X_val_landmarks, y_val = load_images_and_landmarks(selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b34fa721-4652-4997-a53f-ba00cb2d111e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Shape: (39992, 256, 256, 3)\n",
      "Train Landmarks Shape: (39989, 21, 3)\n",
      "Train Labels Shape: (39989,)\n",
      "Test Images Shape: (14000, 256, 256, 3)\n",
      "Test Landmarks Shape: (13995, 21, 3)\n",
      "Test Labels Shape: (13995,)\n",
      "Validation Images Shape: (24190, 256, 256, 3)\n",
      "Validation Landmarks Shape: (24187, 21, 3)\n",
      "Validation Labels Shape: (24187,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Images Shape:\", X_train_images.shape)\n",
    "print(\"Train Landmarks Shape:\", X_train_landmarks.shape)\n",
    "print(\"Train Labels Shape:\", y_train.shape)\n",
    "print(\"Test Images Shape:\", X_test_images.shape)\n",
    "print(\"Test Landmarks Shape:\", X_test_landmarks.shape)\n",
    "print(\"Test Labels Shape:\", y_test.shape)\n",
    "print(\"Validation Images Shape:\", X_val_images.shape)\n",
    "print(\"Validation Landmarks Shape:\", X_val_landmarks.shape)\n",
    "print(\"Validation Labels Shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c90468a6-95d2-43ff-9f2f-9dd8d8a7a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(images, landmarks, labels):\n",
    "    filtered_images = []\n",
    "    filtered_landmarks = []\n",
    "    filtered_labels = []\n",
    "\n",
    "    for img, lnd, lbl in zip(images, landmarks, labels):\n",
    "        if len(lnd) == 49:\n",
    "            filtered_images.append(img)\n",
    "            filtered_landmarks.append(lnd)\n",
    "            filtered_labels.append(lbl)\n",
    "\n",
    "    return (np.array(filtered_images), np.array(filtered_landmarks), np.array(filtered_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07cd9c9c-649c-4d60-a7dd-23b89d847af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_images, X_train_landmarks, y_train = filter_data(X_train_images, X_train_landmarks, y_train)\n",
    "X_test_images, X_test_landmarks, y_test = filter_data(X_test_images, X_test_landmarks, y_test)\n",
    "X_val_images, X_val_landmarks, y_val = filter_data(X_val_images, X_val_landmarks, y_val)\n",
    "\n",
    "\n",
    "assert X_train_images.shape[0] == X_train_landmarks.shape[0] == y_train.shape[0], \"Mismatch in number of training samples\"\n",
    "assert X_test_images.shape[0] == X_test_landmarks.shape[0] == y_test.shape[0], \"Mismatch in number of test samples\"\n",
    "assert X_val_images.shape[0] == X_val_landmarks.shape[0] == y_val.shape[0], \"Mismatch in number of validation samples\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4693555-0b62-4885-ae57-77b4873ddc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(RUNS_DIR / 'X_train_images.npy', X_train_images)\n",
    "np.save(RUNS_DIR / 'X_train_landmarks.npy', X_train_landmarks)\n",
    "np.save(RUNS_DIR / 'y_train.npy', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02dd1e90-523e-451a-9d70-09ebcd872ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(RUNS_DIR / 'X_test_images.npy', X_test_images)\n",
    "np.save(RUNS_DIR / 'X_test_landmarks.npy', X_test_landmarks)\n",
    "np.save(RUNS_DIR / 'y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "338072e6-d276-4c75-adba-dad807b99801",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(RUNS_DIR / 'X_val_images.npy', X_val_images)\n",
    "np.save(RUNS_DIR / 'X_val_landmarks.npy', X_val_landmarks)\n",
    "np.save(RUNS_DIR / 'y_val.npy', y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73379ab-44ab-4763-bcc3-3723f96a3657",
   "metadata": {},
   "source": [
    "MODEL:\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e1bd9cb-a1e2-45d1-86fe-747d02feb31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 254, 254, 32  896         ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 127, 127, 32  0          ['conv2d_3[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 125, 125, 64  18496       ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 62, 62, 64)  0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 60, 60, 128)  73856       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 30, 30, 128)  0          ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 21, 3)]      0           []                               \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 115200)       0           ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 63)           0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          14745728    ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          8192        ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 128)          0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 256)          0           ['dropout_2[0][0]',              \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            257         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,847,425\n",
      "Trainable params: 14,847,425\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_input = Input(shape=(256, 256, 3))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "img_output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "landmark_input = Input(shape=(21, 3))\n",
    "y = Flatten()(landmark_input)\n",
    "y = Dense(128, activation='relu')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "lnd_output = Dense(63, activation='linear')(y)  # 21 landmarks * 3 coordinates = 63\n",
    "\n",
    "combined = Concatenate()([x, y])\n",
    "final_output = Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "model = Model(inputs=[image_input, landmark_input], outputs=[final_output])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68eeb653-788d-4724-b5cd-e5e66d0bef53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1250/1250 [==============================] - 1667s 1s/step - loss: 0.1305 - accuracy: 0.9518 - val_loss: 0.8236 - val_accuracy: 0.8674\n",
      "Epoch 2/5\n",
      "1250/1250 [==============================] - 1801s 1s/step - loss: 0.1223 - accuracy: 0.9579 - val_loss: 0.5843 - val_accuracy: 0.8732\n",
      "Epoch 3/5\n",
      "1250/1250 [==============================] - 1662s 1s/step - loss: 0.1104 - accuracy: 0.9629 - val_loss: 0.7506 - val_accuracy: 0.8817\n",
      "Epoch 4/5\n",
      "1250/1250 [==============================] - 1663s 1s/step - loss: 0.1151 - accuracy: 0.9593 - val_loss: 0.7428 - val_accuracy: 0.8785\n",
      "Epoch 5/5\n",
      "1250/1250 [==============================] - 1663s 1s/step - loss: 0.1129 - accuracy: 0.9608 - val_loss: 0.8331 - val_accuracy: 0.8701\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_images, X_train_landmarks], y_train,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_data=([X_val_images, X_val_landmarks], y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41664599-a3dd-4377-999b-a9c660d98513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 157s 358ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict([X_test_images, X_test_landmarks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9e56e8f-54a3-4c1a-8191-4e72cd7ae072",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = (preds > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88eab57b-22ef-485c-b56e-2477374cdff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6161  837]\n",
      " [ 952 6045]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "c_matrix = confusion_matrix(y_test, predicted_class)\n",
    "print(c_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e3f45a3-d247-400f-bbaf-f3ee61db3162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      6998\n",
      "           1       0.88      0.86      0.87      6997\n",
      "\n",
      "    accuracy                           0.87     13995\n",
      "   macro avg       0.87      0.87      0.87     13995\n",
      "weighted avg       0.87      0.87      0.87     13995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report = classification_report(y_test, predicted_class)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69a6171d-9573-4e82-bea7-40e6b2acc5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(str(WEIGHTS_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2dcfffd9-2d60-4c89-a6fb-a871317fc0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_landmarks_from_extra_test(selected_indices):\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True)\n",
    "\n",
    "    def process_folder(folder_path, label):\n",
    "        images, landmarks, labels = [], [], []\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(root, file)\n",
    "                    image = cv2.imread(img_path)\n",
    "                    if image is None:\n",
    "                        continue\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    resized_image = cv2.resize(image, (256, 256))\n",
    "                    results = face_mesh.process(resized_image)\n",
    "                    if results.multi_face_landmarks:\n",
    "                        fl = results.multi_face_landmarks[0]\n",
    "                        landmark_coords = [(lm.x, lm.y, lm.z) for i, lm in enumerate(fl.landmark) if i in selected_indices]\n",
    "                        images.append(resized_image)\n",
    "                        landmarks.append(landmark_coords)\n",
    "                        labels.append(label)\n",
    "        return (\n",
    "            np.asarray(images, dtype=np.uint8),\n",
    "            np.asarray(landmarks, dtype=np.float32),\n",
    "            np.asarray(labels, dtype=np.int64),\n",
    "        )\n",
    "\n",
    "    base_path = DATA_DIR / \"extra_test\"\n",
    "    imgs, lnds, lbls = [], [], []\n",
    "    for label in [0, 1]:\n",
    "        folder = base_path / str(label)\n",
    "        if not folder.exists():\n",
    "            continue\n",
    "        X, L, y = process_folder(str(folder), label)\n",
    "        imgs.append(X); lnds.append(L); lbls.append(y)\n",
    "\n",
    "    return np.concatenate(imgs, 0), np.concatenate(lnds, 0), np.concatenate(lbls, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02b2dc44-6d79-4490-91ed-b4612a94cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"dataset/extra_test\"\n",
    "X_images_extra, X_landmarks_extra, y_labels_extra = load_images_and_landmarks_from_extra_test(base_path, selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f414761f-5267-47e1-96f4-07aa24ad78bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_images_extra, X_landmarks_extra, y_labels_extra = load_images_and_landmarks_from_extra_test(selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c557c121-c9ed-4790-9612-0f3cf925a334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 14s 343ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict([X_images_extra, X_landmarks_extra])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "58b465df-abe7-453a-85cb-b0a8ed6d00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = (preds > 0.05).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d5cfb044-4b6a-465a-99f0-b4781b6fff7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 53 521]\n",
      " [ 69 631]]\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_labels_extra, predicted_class)\n",
    "print(c_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4238adb4-dd3e-4356-a1e4-7addfffd93f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.09      0.15       574\n",
      "           1       0.55      0.90      0.68       700\n",
      "\n",
      "    accuracy                           0.54      1274\n",
      "   macro avg       0.49      0.50      0.42      1274\n",
      "weighted avg       0.50      0.54      0.44      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report = classification_report(y_labels_extra, predicted_class)\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
